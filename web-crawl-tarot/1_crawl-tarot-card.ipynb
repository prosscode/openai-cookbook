{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cff86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url https://trustedtarot.com/cards/\n",
    "# 78 Tarot Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb6453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "from html.parser import HTMLParser\n",
    "from urllib.parse import urlparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "166b9515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://trustedtarot.com/cards\n",
      "https://trustedtarot.com/cards/queen-of-pentacles\n",
      "https://trustedtarot.com/cards/judgement\n",
      "https://trustedtarot.com/cards/page-of-pentacles\n",
      "https://trustedtarot.com/cards/six-of-wands\n",
      "https://trustedtarot.com/cards/five-of-swords\n",
      "https://trustedtarot.com/cards/seven-of-pentacles\n",
      "https://trustedtarot.com/cards/queen-of-swords\n",
      "https://trustedtarot.com/cards/the-world\n",
      "https://trustedtarot.com/cards/three-of-wands\n",
      "https://trustedtarot.com/cards/queen-of-wands\n",
      "https://trustedtarot.com/cards/ten-of-swords\n",
      "https://trustedtarot.com/cards/temperance\n",
      "https://trustedtarot.com/cards/four-of-wands\n",
      "https://trustedtarot.com/cards/nine-of-wands\n",
      "https://trustedtarot.com/cards/eight-of-cups\n",
      "https://trustedtarot.com/cards/strength\n",
      "https://trustedtarot.com/cards/king-of-swords\n",
      "https://trustedtarot.com/cards/the-magician\n",
      "https://trustedtarot.com/cards/ten-of-pentacles\n",
      "https://trustedtarot.com/cards/ten-of-cups\n",
      "https://trustedtarot.com/cards/knight-of-pentacles\n",
      "https://trustedtarot.com/cards/the-hierophant\n",
      "https://trustedtarot.com/cards/six-of-swords\n",
      "https://trustedtarot.com/cards/queen-of-cups\n",
      "https://trustedtarot.com/cards/two-of-swords\n",
      "https://trustedtarot.com/cards/the-hermit\n",
      "https://trustedtarot.com/cards/five-of-wands\n",
      "https://trustedtarot.com/cards/ten-of-wands\n",
      "https://trustedtarot.com/cards/page-of-cups\n",
      "https://trustedtarot.com/cards/six-of-cups\n",
      "https://trustedtarot.com/cards/the-lovers\n",
      "https://trustedtarot.com/cards/two-of-pentacles\n",
      "https://trustedtarot.com/cards/nine-of-swords\n",
      "https://trustedtarot.com/cards/justice\n",
      "https://trustedtarot.com/cards/death\n",
      "https://trustedtarot.com/cards/page-of-swords\n",
      "https://trustedtarot.com/cards/ace-of-pentacles\n",
      "https://trustedtarot.com/cards/seven-of-wands\n",
      "https://trustedtarot.com/cards/seven-of-cups\n",
      "https://trustedtarot.com/cards/the-emperor\n",
      "https://trustedtarot.com/cards/the-empress\n",
      "https://trustedtarot.com/cards/the-devil\n",
      "https://trustedtarot.com/cards/four-of-pentacles\n",
      "https://trustedtarot.com/cards/two-of-cups\n",
      "https://trustedtarot.com/cards/three-of-pentacles\n",
      "https://trustedtarot.com/cards/five-of-pentacles\n",
      "https://trustedtarot.com/cards/the-tower\n",
      "https://trustedtarot.com/cards/knight-of-swords\n",
      "https://trustedtarot.com/cards/three-of-swords\n",
      "https://trustedtarot.com/cards/the-fool\n",
      "https://trustedtarot.com/cards/eight-of-pentacles\n",
      "https://trustedtarot.com/cards/king-of-cups\n",
      "https://trustedtarot.com/cards/wheel-of-fortune\n",
      "https://trustedtarot.com/cards/the-sun\n",
      "https://trustedtarot.com/cards/four-of-cups\n",
      "https://trustedtarot.com/cards/ace-of-swords\n",
      "https://trustedtarot.com/cards/three-of-cups\n",
      "https://trustedtarot.com/cards/king-of-wands\n",
      "https://trustedtarot.com/cards/nine-of-pentacles\n",
      "https://trustedtarot.com/cards/the-moon\n",
      "https://trustedtarot.com/cards/ace-of-wands\n",
      "https://trustedtarot.com/cards/ace-of-cups\n",
      "https://trustedtarot.com/cards/four-of-swords\n",
      "https://trustedtarot.com/cards/seven-of-swords\n",
      "https://trustedtarot.com/cards/eight-of-wands\n",
      "https://trustedtarot.com/cards/nine-of-cups\n",
      "https://trustedtarot.com/cards/the-star\n",
      "https://trustedtarot.com/cards/the-high-priestess\n",
      "https://trustedtarot.com/cards/king-of-pentacles\n",
      "https://trustedtarot.com/cards/knight-of-wands\n",
      "https://trustedtarot.com/cards/eight-of-swords\n",
      "https://trustedtarot.com/cards/the-chariot\n",
      "https://trustedtarot.com/cards/knight-of-cups\n",
      "https://trustedtarot.com/cards/five-of-cups\n",
      "https://trustedtarot.com/cards/six-of-pentacles\n",
      "https://trustedtarot.com/cards/two-of-wands\n",
      "https://trustedtarot.com/cards/the-hanged-man\n",
      "https://trustedtarot.com/cards/page-of-wands\n"
     ]
    }
   ],
   "source": [
    "# Regex pattern to match a URL\n",
    "HTTP_URL_PATTERN = r'^http[s]*://.+'\n",
    "# Define root domain to crawl\n",
    "domain = \"trustedtarot.com\"\n",
    "full_url = \"https://trustedtarot.com/cards\"\n",
    "\n",
    "\n",
    "# Create a class to parse the HTML and get the hyperlinks\n",
    "class HyperlinkParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Create a list to store the hyperlinks\n",
    "        self.hyperlinks = []\n",
    "\n",
    "    # Override the HTMLParser's handle_starttag method to get the hyperlinks\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        attrs = dict(attrs)\n",
    "\n",
    "        # If the tag is an anchor tag and it has an href attribute, add the href attribute to the list of hyperlinks\n",
    "        if tag == \"a\" and \"href\" in attrs:\n",
    "            self.hyperlinks.append(attrs[\"href\"])\n",
    "\n",
    "\n",
    "# Function to get the hyperlinks from a URL\n",
    "def get_hyperlinks(url):\n",
    "    # Try to open the URL and read the HTML\n",
    "    try:\n",
    "        hdr = {\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "            'Accept-Encoding': 'none',\n",
    "            'Accept-Language': 'en-US,en;q=0.8',\n",
    "            'Connection': 'keep-alive'}\n",
    "        # The assembled request\n",
    "        request = urllib.request.Request(url, None, hdr)\n",
    "        # Open the URL and read the HTML\n",
    "        with urllib.request.urlopen(request) as response:\n",
    "\n",
    "            # If the response is not HTML, return an empty list\n",
    "            if not response.info().get('Content-Type').startswith(\"text/html\"):\n",
    "                return []\n",
    "\n",
    "            # Decode the HTML\n",
    "            html = response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "    # Create the HTML Parser and then Parse the HTML to get hyperlinks\n",
    "    parser = HyperlinkParser()\n",
    "    parser.feed(html)\n",
    "\n",
    "    return parser.hyperlinks\n",
    "\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    for link in set(get_hyperlinks(url)):\n",
    "        clean_link = None\n",
    "\n",
    "        # If the link is a URL, check if it is within the same domain\n",
    "        if re.search(HTTP_URL_PATTERN, link):\n",
    "            # Parse the URL and check if the domain is the same\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain:\n",
    "                clean_link = link\n",
    "\n",
    "        # If the link is not a URL, check if it is a relative link\n",
    "        else:\n",
    "            if link.startswith(\"/\"):\n",
    "                link = link[1:]\n",
    "            elif link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
    "                continue\n",
    "            clean_link = \"https://\" + local_domain + \"/\" + link\n",
    "\n",
    "        if clean_link is not None:\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            if \"cards\" not in clean_link:\n",
    "                continue\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    # Return the list of hyperlinks that are within the same domain\n",
    "    return list(set(clean_links))\n",
    "\n",
    "\n",
    "def crawl(url):\n",
    "    # Parse the URL and get the domain\n",
    "    local_domain = urlparse(url).netloc\n",
    "\n",
    "    # Create a queue to store the URLs to crawl\n",
    "    queue = deque([url])\n",
    "\n",
    "    # Create a set to store the URLs that have already been seen (no duplicates)\n",
    "    seen = set([url])\n",
    "\n",
    "    # Create a directory to store the text files\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "\n",
    "    if not os.path.exists(\"text/\" + local_domain + \"/\"):\n",
    "        os.mkdir(\"text/\" + local_domain + \"/\")\n",
    "\n",
    "    # Create a directory to store the csv files\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    # While the queue is not empty, continue crawling\n",
    "    while queue:\n",
    "\n",
    "        # Get the next URL from the queue\n",
    "        url = queue.pop()\n",
    "        print(url)  # for debugging and to see the progress\n",
    "\n",
    "        # Save text from the url to a <url>.txt file\n",
    "        with open('text/' + local_domain + '/' + url[8:].replace(\"/\", \"_\") + \".txt\", \"w\") as f:\n",
    "\n",
    "            # Get the text from the URL using BeautifulSoup\n",
    "            soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "            # Get the text but remove the tags\n",
    "            text = soup.get_text()\n",
    "\n",
    "            # If the crawler gets to a page that requires JavaScript, it will stop the crawl\n",
    "            if (\"You need to enable JavaScript to run this app.\" in text):\n",
    "                print(\"Unable to parse page \" + url + \" due to JavaScript being required\")\n",
    "\n",
    "            # Otherwise, write the text to the file in the text directory\n",
    "            f.write(text)\n",
    "\n",
    "        # Get the hyperlinks from the URL and add them to the queue\n",
    "        for link in get_domain_hyperlinks(local_domain, url):\n",
    "            if link not in seen:\n",
    "                queue.append(link)\n",
    "                seen.add(link)\n",
    "\n",
    "crawl(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2c491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.str.replace('\\n', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0a9de79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cards ace of cups</td>\n",
       "      <td>Ace of Cups Tarot Card Meaning     Free Taro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cards page of wands</td>\n",
       "      <td>Page of Wands Tarot Card Meaning     Free Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cards six of pentacles</td>\n",
       "      <td>Six of Pentacles Tarot Card Meaning     Free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cards the star</td>\n",
       "      <td>The Star Tarot Card Meaning     Free Tarot R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cards queen of swords</td>\n",
       "      <td>Queen of Swords Tarot Card Meaning     Free ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cards four of swords</td>\n",
       "      <td>Four of Swords Tarot Card Meaning     Free T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cards ace of swords</td>\n",
       "      <td>Ace of Swords Tarot Card Meaning     Free Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cards the chariot</td>\n",
       "      <td>The Chariot Tarot Card Meaning     Free Taro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cards the hanged man</td>\n",
       "      <td>The Hanged Man Tarot Card Meaning     Free T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cards seven of swords</td>\n",
       "      <td>Seven of Swords Tarot Card Meaning!     Free...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fname                                               text\n",
       "0       cards ace of cups    Ace of Cups Tarot Card Meaning     Free Taro...\n",
       "1     cards page of wands    Page of Wands Tarot Card Meaning     Free Ta...\n",
       "2  cards six of pentacles    Six of Pentacles Tarot Card Meaning     Free...\n",
       "3          cards the star    The Star Tarot Card Meaning     Free Tarot R...\n",
       "4   cards queen of swords    Queen of Swords Tarot Card Meaning     Free ...\n",
       "5    cards four of swords    Four of Swords Tarot Card Meaning     Free T...\n",
       "6     cards ace of swords    Ace of Swords Tarot Card Meaning     Free Ta...\n",
       "7       cards the chariot    The Chariot Tarot Card Meaning     Free Taro...\n",
       "8    cards the hanged man    The Hanged Man Tarot Card Meaning     Free T...\n",
       "9   cards seven of swords    Seven of Swords Tarot Card Meaning!     Free..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Regex pattern to match a URL\n",
    "HTTP_URL_PATTERN = r'^http[s]*://.+'\n",
    "# Define root domain to crawl\n",
    "domain = \"trustedtarot.com\"\n",
    "full_url = \"https://trustedtarot.com/cards\"\n",
    "\n",
    "# Create a list to store the text files\n",
    "texts=[]\n",
    "# Get all the text files in the text directory\n",
    "for file in os.listdir(\"text/\" + domain + \"/\"):\n",
    "\n",
    "    # Open the file and read the text\n",
    "    with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Omit the first 11 lines and the last 4 lines, then replace -, _, and #update with spaces.\n",
    "        texts.append((file[17:-4].replace('-',' ').replace('_', ' ').replace('#update',''), text))\n",
    "\n",
    "\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(texts, columns = ['fname', 'text'])\n",
    "\n",
    "# Set the text column to be the raw text with the newlines removed\n",
    "df['text'] = remove_newlines(df.text)\n",
    "# df['text'] = df['text'].str.slice(stop=-405)\n",
    "df['text'] = df['text'].str.split('Key Dates, Timing').str[0]\n",
    "df['text'] = remove_newlines(df.text)\n",
    "df.to_csv('processed/scraped_1.csv')\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
